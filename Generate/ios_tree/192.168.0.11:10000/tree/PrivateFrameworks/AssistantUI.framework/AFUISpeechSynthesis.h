/* Generated by RuntimeBrowser
   Image: /System/Library/PrivateFrameworks/AssistantUI.framework/AssistantUI
 */

@interface AFUISpeechSynthesis : NSObject <AFQueueDelegate, AFUIPowerLevelListenerDelegate, AFUISpeechSynthesis, AFUISpeechSynthesisElementDelegate, VSSpeechSynthesizerDelegate> {
    NSMutableArray * _activeElements;
    NSMutableDictionary * _availableVoicesForLanguage;
    NSMutableDictionary * _delayedElements;
    <AFUISpeechSynthesisDelegate> * _delegate;
    AFQueue * _elementQueue;
    <AFUISpeechSynthesisLocalDelegate> * _localDelegate;
    AFVoiceInfo * _outputVoice;
    NSObject<OS_dispatch_group> * _pendingElementsGroup;
    NSObject<OS_dispatch_queue> * _pendingElementsQueue;
    AFUIPowerLevelListener * _powerLevelListener;
    NSObject<OS_dispatch_queue> * _processingElementsQueue;
    unsigned int  _sessionID;
    AFSiriClientStateManager * _siriClientStateManager;
    VSSpeechSynthesizer * _synthesizer;
}

@property (getter=_activeElements, nonatomic, readonly) NSMutableArray *activeElements;
@property (readonly, copy) NSString *debugDescription;
@property (getter=_delayedElements, nonatomic, readonly) NSMutableDictionary *delayedElements;
@property (nonatomic, retain) <AFUISpeechSynthesisDelegate> *delegate;
@property (readonly, copy) NSString *description;
@property (getter=_elementQueue, nonatomic, readonly) AFQueue *elementQueue;
@property (readonly) unsigned long long hash;
@property (nonatomic) <AFUISpeechSynthesisLocalDelegate> *localDelegate;
@property (readonly) Class superclass;

- (void).cxx_destruct;
- (id)_activeElementWithPresynthesizedAudioRequest:(id)arg1;
- (id)_activeElementWithSpeechRequest:(id)arg1;
- (id)_activeElements;
- (void)_cancelByCancellingActiveElementsOnly:(bool)arg1;
- (id)_delayedElements;
- (id)_elementQueue;
- (void)_enqueueText:(id)arg1 audioData:(id)arg2 identifier:(id)arg3 language:(id)arg4 gender:(id)arg5 isPhonetic:(bool)arg6 provisionally:(bool)arg7 eligibleAfterDuration:(double)arg8 delayed:(bool)arg9 canUseServerTTS:(bool)arg10 preparationIdentifier:(id)arg11 shouldCache:(bool)arg12 synthesizesWhileRecording:(bool)arg13 completion:(id /* block */)arg14 animationIdentifier:(id)arg15 analyticsContext:(id)arg16 speakableContextInfo:(id)arg17;
- (id)_filterVoices:(id)arg1 gender:(id)arg2;
- (void)_findVoiceForLanguage:(id)arg1 gender:(id)arg2 completion:(id /* block */)arg3;
- (long long)_genderForString:(id)arg1;
- (void)_handleAudioData:(id)arg1 completion:(id /* block */)arg2;
- (void)_handleText:(id)arg1 completion:(id /* block */)arg2;
- (bool)_isSynthesisQueueEmpty;
- (void)_processElementQueue;
- (void)_processProvisionalElements;
- (void)_setSiriClientStateManager:(id)arg1;
- (void)_setSynthesizer:(id)arg1;
- (id)_siriClientStateManager;
- (id)_synthesizer;
- (void)cancel;
- (id)delegate;
- (void)enqueueAudioData:(id)arg1 identifier:(id)arg2 provisionally:(bool)arg3 eligibleAfterDuration:(double)arg4 completion:(id /* block */)arg5;
- (void)enqueuePhaticWithCompletion:(id /* block */)arg1;
- (void)enqueueText:(id)arg1 identifier:(id)arg2 completion:(id /* block */)arg3;
- (void)enqueueText:(id)arg1 identifier:(id)arg2 language:(id)arg3 gender:(id)arg4 isPhonetic:(bool)arg5 provisionally:(bool)arg6 eligibleAfterDuration:(double)arg7 delayed:(bool)arg8 canUseServerTTS:(bool)arg9 preparationIdentifier:(id)arg10 completion:(id /* block */)arg11 animationIdentifier:(id)arg12 analyticsContext:(id)arg13 speakableContextInfo:(id)arg14;
- (id)init;
- (void)invalidate;
- (void)invalidateOnMainThread;
- (bool)isSpeaking;
- (void)isSynthesisQueueEmpty:(id /* block */)arg1;
- (id)localDelegate;
- (void)powerLevelListener:(id)arg1 powerLevelDidUpdateTo:(float)arg2;
- (void)prewarmIfNeeded;
- (void)processDelayedItem:(id)arg1;
- (void)queue:(id)arg1 didEnqueueObjects:(id)arg2;
- (void)setAudioSessionID:(unsigned int)arg1;
- (void)setDelegate:(id)arg1;
- (void)setLocalDelegate:(id)arg1;
- (void)setOutputVoice:(id)arg1;
- (void)skipCurrentSynthesis;
- (void)speechSynthesisElementSynthesisEligibilityDidChange:(id)arg1;
- (void)speechSynthesizer:(id)arg1 didFinishPresynthesizedAudioRequest:(id)arg2 withInstrumentMetrics:(id)arg3 error:(id)arg4;
- (void)speechSynthesizer:(id)arg1 didFinishSpeakingRequest:(id)arg2 successfully:(bool)arg3 phonemesSpoken:(id)arg4 withError:(id)arg5;
- (void)speechSynthesizer:(id)arg1 didFinishSpeakingRequest:(id)arg2 withInstrumentMetrics:(id)arg3;
- (void)speechSynthesizer:(id)arg1 didStartPresynthesizedAudioRequest:(id)arg2;
- (void)speechSynthesizer:(id)arg1 didStartSpeakingRequest:(id)arg2;
- (void)speechSynthesizer:(id)arg1 didStopPresynthesizedAudioRequest:(id)arg2 atEnd:(bool)arg3 error:(id)arg4;

@end
